{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "first-necklace",
   "metadata": {},
   "source": [
    "## Capstone Check-in #2 \n",
    "Dustin Stewart  \n",
    "DSIR 2-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-keyboard",
   "metadata": {},
   "source": [
    "**Problem:**   \n",
    "Due to the unpredictable and expansive nature of the sport, it remains hard for football clubs to properly assess the value of prospective signings. Much of the previous techniques relied on scouting players in person and mostly semi-educated gambling. The result is an enormous amount of poor performing signings in the football world. In this project, I will develop a machine learning model that will predict a players average goals and assists per game over the next 3 years using aggregated historical time series data as well as global data. Those predictions can then be used to find the highest performing players relative to their estimated value. For example, you could get a list of players who are predicted to average more than 0.5 goals a match and then rank them by ascending estimated market value (cheapest first). You would then look to purchase the cheaper players or further scout them in person."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-advisory",
   "metadata": {},
   "source": [
    "**Data Collection:**  \n",
    "Collected from TransferMarkt, one of the most extensive online collections of football stats. I scraped using a function that navigates to each player from the top 10 leagues in Europe and scrapes their [full stats](https://www.transfermarkt.us/sadio-mane/leistungsdatendetails/spieler/200512/plus/0?saison=&verein=&liga=&wettbewerb=&pos=&trainer_id=)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-edition",
   "metadata": {},
   "source": [
    "**EDA Methods:**  \n",
    "Considering using ratios for values. If a player scores 5 goals in 3 matches, that's much better than somebody who scores 6 goals in 40 matches.\n",
    "\n",
    "We're looking at players who are 20-26 in 2016, because we're only interested in younger players who are less injury prone and will give us value longer and we can resell at their peak for a profit. \n",
    "\n",
    "I will be removing all players with very little playing data. If they don't have senior playing experience, then we're not interested in those players. At least not at this point. I'd need to gather data that isn't easily available and is not related to the purpose of this project.\n",
    "\n",
    "All players who don't play in attacking positions won't be used. I want to predict attacking player performance for the purpose of this project and to keep a reasonable scope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-poverty",
   "metadata": {},
   "source": [
    "**Risks, Assumptions, General Concerns Going into the Future:**  \n",
    "It's not clear that this data will be enough to make accurate predictions even if it's aggregated. Football is an inherently unpredictable game and stats don't tell as much as most other sports. That being said, sometimes there's patterns that human minds cannot comprehend and that's the goal for the project. Also, there's just many factors that can't be taken into account by data. This is why football has been reluctant to adopt data-centric player recruitment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-seating",
   "metadata": {},
   "source": [
    "**Scraping function that isn't polished yet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_request = requests.get('https://www.transfermarkt.us/wettbewerbe/europa', headers={'User-Agent': 'Custom5'})\n",
    "home_html = home_request.text\n",
    "home_soup = BeautifulSoup(home_html, 'lxml')\n",
    "leagues_table = home_soup.find_all('table')\n",
    "leagues_table = leagues_table[0].find_all('a')[4:60]\n",
    "full_list = []\n",
    "league_urls = []\n",
    "for string in leagues_table:\n",
    "    if 'startseite' in string['href'] and '1' in string['href'] and string['href'][-2] != '+':\n",
    "        league_urls.append(string['href'])\n",
    "for league_url in league_urls[8:9]:\n",
    "    league_dict = {}\n",
    "    \n",
    "    league_name = league_url[1:league_url.find('/startseite')]\n",
    "    home_request = requests.get('https://www.transfermarkt.us' + league_url + '/plus/?saison_id=2010', headers={'User-Agent': 'Custom5'})\n",
    "    home_html = home_request.text\n",
    "    home_soup = BeautifulSoup(home_html, 'lxml')\n",
    "    clubs_table = home_soup.find_all('table')[3]\n",
    "    clubs_table_tags = clubs_table.find_all('a')\n",
    "    club_urls = []\n",
    "    for string in clubs_table_tags:\n",
    "        if 'startseite' in string['href'] and 'saison' in string['href'] and string['href'] not in club_urls:\n",
    "            club_urls.append(string['href'])\n",
    "    for club_url in club_urls[10:11]:\n",
    "        print(club_url)\n",
    "        print(len(club_urls))\n",
    "        club_dict = {}\n",
    "        \n",
    "        club_name = club_url[1:club_url.find('/startseite')]\n",
    "        \n",
    "        \n",
    "        \n",
    "        home_request = requests.get('https://www.transfermarkt.us' + club_url[:-4] + '2010', headers={'User-Agent': 'Custom5'})\n",
    "        home_html = home_request.text\n",
    "        home_soup = BeautifulSoup(home_html, 'lxml')\n",
    "        players_table = home_soup.find_all('table')[1]\n",
    "        players_table_tags = players_table.find_all('a')\n",
    "        player_urls = []\n",
    "        for string in players_table_tags:\n",
    "            if 'spieler' in string['href'] and 'profil' in string['href'] and string['href'] not in player_urls:\n",
    "                player_urls.append(string['href'])\n",
    "        for player_url in player_urls[:]:\n",
    "            \n",
    "            \n",
    "            \n",
    "            player_dict = {}\n",
    "            \n",
    "            url1 = 'http://www.transfermarkt.us' + player_url[0:-21] + '/leistungsdatendetails/' + player_url[-13:] + '/saison//verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1'\n",
    "            url2 = 'http://www.transfermarkt.us' + player_url[0:-22] + '/leistungsdatendetails/' + player_url[-14:] + '/saison//verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1'\n",
    "            url3 = 'http://www.transfermarkt.us' + player_url[0:-20] + '/leistungsdatendetails/' + player_url[-12:] + '/saison//verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1'\n",
    "            try:\n",
    "    \n",
    "                \n",
    "                if url1.count('/') == 20:\n",
    "\n",
    "                    print('url1:')\n",
    "                    print(url1)\n",
    "                    player_name = url1[28:-98].replace('-', '_')\n",
    "\n",
    "                    home_request = requests.get(url1, headers={'User-Agent': 'Custom5'})\n",
    "                    home_html = home_request.text\n",
    "                    home_soup = BeautifulSoup(home_html, 'lxml')\n",
    "                    player_table = home_soup.find_all('table', {\"class\": 'items'})[0]\n",
    "\n",
    "                    player_clubs = player_table.find_all(\"a\", {\"class\": 'vereinprofil_tooltip'})\n",
    "                    club_column = []\n",
    "                    for club in player_clubs:\n",
    "                        \n",
    "                        club_column.append(club['href'][1:club['href'].find('/startseite')])\n",
    "                    df = pd.read_html(str(player_table))\n",
    "\n",
    "                    df = df[0]\n",
    "\n",
    "\n",
    "                    df.drop(df.columns[-1], axis=1, inplace = True)\n",
    "\n",
    "                    df.drop(index = len(df)-1, inplace = True)\n",
    "\n",
    "                    df.drop(df.columns[9:-1], axis=1, inplace = True)\n",
    "                    \n",
    "                    df.drop(df.columns[1], axis=1, inplace = True)\n",
    "                    df.drop(df.columns[2], axis=1, inplace = True)\n",
    "                    column_names = ['season', 'competition', 'in_squad', 'appearances', 'points_per_match', 'goals', 'assists', 'minutes_played']\n",
    "                    to_rename = dict(zip(df.columns, column_names))\n",
    "\n",
    "                    df.rename(columns = to_rename, inplace = True)\n",
    "                    df['club'] = club_column\n",
    "                    player_dict[url1[28:-98].replace('-', '_') + ', ' + club_name + ', ' + league_name] = df\n",
    "                    full_list.append(player_dict)\n",
    "\n",
    "                elif url2.count('/') == 20:\n",
    "                    print('url2:')\n",
    "                    print(url2)\n",
    "                    player_name = url1[28:-99].replace('-', '_')\n",
    "\n",
    "\n",
    "                    home_request = requests.get(url2, headers={'User-Agent': 'Custom5'})\n",
    "                    home_html = home_request.text\n",
    "                    home_soup = BeautifulSoup(home_html, 'lxml')\n",
    "                    player_table = home_soup.find_all('table', {\"class\": 'items'})[0]\n",
    "                    player_clubs = player_table.find_all(\"a\", {\"class\": 'vereinprofil_tooltip'})\n",
    "                    club_column = []\n",
    "                    for club in player_clubs:\n",
    "                        \n",
    "                        club_column.append(club['href'][1:club['href'].find('/startseite')])\n",
    "                    df = pd.read_html(str(player_table))\n",
    "\n",
    "                    df = df[0]\n",
    "\n",
    "\n",
    "                    df.drop(df.columns[-1], axis=1, inplace = True)\n",
    "\n",
    "                    df.drop(index = len(df)-1, inplace = True)\n",
    "\n",
    "                    df.drop(df.columns[9:-1], axis=1, inplace = True)\n",
    "                    \n",
    "                    df.drop(df.columns[1], axis=1, inplace = True)\n",
    "                    df.drop(df.columns[2], axis=1, inplace = True)\n",
    "                    column_names = ['season', 'competition', 'in_squad', 'appearances', 'points_per_match', 'goals', 'assists', 'minutes_played']\n",
    "                    to_rename = dict(zip(df.columns, column_names))\n",
    "\n",
    "                    df.rename(columns = to_rename, inplace = True)\n",
    "                    df['club'] = club_column\n",
    "                    player_dict[url2[28:-99].replace('-', '_') + ', ' + club_name + ', ' + league_name] = df\n",
    "                    full_list.append(player_dict)\n",
    "\n",
    "\n",
    "                elif url3.count('/') == 20:\n",
    "                    print('url3:')\n",
    "                    print(url3)\n",
    "                    player_name = url3[28:-97].replace('-', '_')\n",
    "\n",
    "                    home_request = requests.get(url3, headers={'User-Agent': 'Custom5'})\n",
    "                    home_html = home_request.text\n",
    "                    home_soup = BeautifulSoup(home_html, 'lxml')\n",
    "                    player_table = home_soup.find_all('table', {\"class\": 'items'})[0]\n",
    "                    player_clubs = player_table.find_all(\"a\", {\"class\": 'vereinprofil_tooltip'})\n",
    "                    club_column = []\n",
    "                    for club in player_clubs:\n",
    "                        \n",
    "                        club_column.append(club['href'][1:club['href'].find('/startseite')])\n",
    "                    df = pd.read_html(str(player_table))\n",
    "\n",
    "                    df = df[0]\n",
    "\n",
    "\n",
    "                    df.drop(df.columns[-1], axis=1, inplace = True)\n",
    "\n",
    "                    df.drop(index = len(df)-1, inplace = True)\n",
    "\n",
    "                    df.drop(df.columns[9:-1], axis=1, inplace = True)\n",
    "                    \n",
    "                    df.drop(df.columns[1], axis=1, inplace = True)\n",
    "                    df.drop(df.columns[2], axis=1, inplace = True)\n",
    "                    column_names = ['season', 'competition', 'in_squad', 'appearances', 'points_per_match', 'goals', 'assists', 'minutes_played']\n",
    "                    to_rename = dict(zip(df.columns, column_names))\n",
    "\n",
    "                    df.rename(columns = to_rename, inplace = True)\n",
    "                    df['club'] = club_column\n",
    "                    player_dict[url3[28:-97].replace('-', '_')] = df\n",
    "                    full_list.append(player_dict)\n",
    "\n",
    "            except:\n",
    "                continue \n",
    "len(full_list)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
